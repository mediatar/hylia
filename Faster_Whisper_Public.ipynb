{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Transcription and Translation\n",
        "\n",
        "AdvancedCI.\n",
        "\n",
        "For technical assistance contact beining@chineseaci.com ."
      ],
      "metadata": {
        "id": "8Ae5bC36S-tM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "5UE-fLMTS8_M",
        "outputId": "601772fa-47fa-4095-dc03-625e93c62ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb  3 23:39:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title GPU Check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install and Setup\n",
        "\n",
        "Execute all steps."
      ],
      "metadata": {
        "id": "aYgBcudUTDrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.1 Install\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install faster-whisper\n",
        "!pip install srt requests tqdm googletrans==4.0.0rc1 httpx aiometer\n",
        "# https://stackoverflow.com/a/77671445\n",
        "!apt install libcublas11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "QhZXEojSTIMM",
        "outputId": "25a8f307-9261-4032-a908-9146f585157c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster-whisper\n",
            "  Downloading faster-whisper-0.10.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==10.* (from faster-whisper)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.22 (from faster-whisper)\n",
            "  Downloading ctranslate2-3.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.15.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.22->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.22->faster-whisper) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.22->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper) (23.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Building wheels for collected packages: faster-whisper\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-0.10.0-py3-none-any.whl size=1539726 sha256=2a71200da92e7a98db78085271c618cd2c2c56d9ec2e16d1c9a15f6437318747\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/4e/9a/bd36d2645cb73f909a3a65a2e317fec5c6a79c8121ab9eb42f\n",
            "Successfully built faster-whisper\n",
            "Installing collected packages: av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.24.0 faster-whisper-0.10.0 humanfriendly-10.0 onnxruntime-1.17.0\n",
            "Collecting srt\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiometer\n",
            "  Downloading aiometer-0.5.0-py3-none-any.whl (12 kB)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2023.11.17)\n",
            "Collecting hstspreload (from httpx)\n",
            "  Downloading hstspreload-2024.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: anyio<5,>=3.2 in /usr/local/lib/python3.10/dist-packages (from aiometer) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from aiometer) (1.2.0)\n",
            "Building wheels for collected packages: googletrans, srt\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=7033fd9adfef6c786dfb28fddb9fe9a312f08bb2bf1bd791b87e73b9ab0dfb01\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=e56a30b18b67f47320fdc7d898ae65e90239ebd5e994cd70b094248b60f8b668\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built googletrans srt\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, srt, idna, hstspreload, h2, httpcore, httpx, aiometer, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "Successfully installed aiometer-0.5.0 chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.2.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0 srt-3.5.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcublaslt11\n",
            "The following NEW packages will be installed:\n",
            "  libcublas11 libcublaslt11\n",
            "0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 226 MB of archives.\n",
            "After this operation, 498 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublaslt11 amd64 11.7.4.6~11.5.1-1ubuntu1 [148 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [78.2 MB]\n",
            "Fetched 226 MB in 6s (37.5 MB/s)\n",
            "Selecting previously unselected package libcublaslt11:amd64.\n",
            "(Reading database ... 121730 files and directories currently installed.)\n",
            "Preparing to unpack .../libcublaslt11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcublas11:amd64.\n",
            "Preparing to unpack .../libcublas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Config\n",
        "\n",
        "### Whisper\n",
        "- `device`: `cuda` or `cpu`. Whether to use GPU.\n",
        "- `model_size`: Name of model. `distil` models are faster with lower quality.\n",
        "- `compute_type`: `float16` is FP16 by default; `int8_float16` is INT8 on GPU; `int8` is INT8 on CPU\n",
        "- `beam_size`: Whisper was trained with this - do not change unless you know what you are doing\n",
        "\n",
        "### Silero VAD\n",
        "- `vad_filter`: Whether to use VAD. Recommended to reduce false positive.\n",
        "- `threshold`: Probability of non-speech. Higher = stricter.\n",
        "- `min_speech_duration_ms`: as name suggests.\n",
        "- `max_speech_duration_s`: Max duration of single speach. Reduced from infinite to 12s.\n",
        "- `min_silence_duration_ms`: In the end of each speech chunk wait for this before separating it\n",
        "- `window_size_samples`: Do not change unless you know what you are doing.\n",
        "- `speech_pad_ms`: Add this to the beginning and end of VAD chunk to reduce false negative.\n",
        "\n",
        "### SRT Generation\n",
        "\n",
        "_This setup is very much ACICFG opinionated._\n",
        "\n",
        "The following combination of setup should achive:\n",
        "\n",
        "1. Any single line of subtitle should not become too long to show in a single line per default font and size setup; AND,\n",
        "2. Any single line of subtitle should be long enough to give viewers enough time to recognize.\n",
        "\n",
        "- `max_text_len`: Maximum characters per line to avoid out of vision. Best-effort basis. See `max_segment_interval`. Address point 1.\n",
        "- `max_segment_interval`: Consider the next chunk of sentence if the length of current line is less than this amount of time. Address point 2.\n"
      ],
      "metadata": {
        "id": "gm1O-arlVRd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings\n",
        "\n",
        "# Whisper\n",
        "device = \"cuda\" #@param [\"cuda\", \"cpu\"]\n",
        "model_size = 'large-v3' #@param [\"large-v3\", \"distil-large-v2\", \"distil-medium.en\"]\n",
        "compute_type = \"float16\" #@param [\"float16\", \"int8_float16\", \"int8\"]\n",
        "beam_size = 5 #@param {type:\"integer\"}\n",
        "whisper_debug = True #@param {type: \"boolean\"}\n",
        "# Silero VAD\n",
        "vad_filter = True #@param {type:\"boolean\"}\n",
        "threshold = 0.5 #@param {type:\"number\"}\n",
        "min_speech_duration_ms = 250 #@param {type:\"integer\"}\n",
        "max_speech_duration_s = 12 #@param {type:\"number\"}\n",
        "min_silence_duration_ms = 2000  #@param {type:\"integer\"}\n",
        "window_size_samples = 1024 #@param [512, 1024, 1536]\n",
        "speech_pad_ms = 400 #@param {type:\"integer\"}\n",
        "# SRT Generation\n",
        "use_whisper_sentence_segment = False #@param {type: \"boolean\"}\n",
        "max_text_len = 110 #@param {type:\"integer\"}\n",
        "max_segment_interval = 1.5 #@param {type:\"number\"}\n",
        "# transcription_cutoff_char = 80 #@param {type:\"integer\"}\n",
        "# align_extend = 2 #@param {type:\"integer\"}\n",
        "# align_from_prev = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B6n6q86hTzJE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3 Load Model\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"faster_whisper\").setLevel(logging.DEBUG)\n",
        "\n",
        "model = WhisperModel(model_size, device=device, compute_type=compute_type)"
      ],
      "metadata": {
        "id": "b5xr2FOqVZ0K",
        "cellView": "form"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Transcribe and Alignment"
      ],
      "metadata": {
        "id": "BaiktMK1Vt4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.1 Setup filename\n",
        "\n",
        "filename = \"output.mp3\" #@param {type:\"string\"}\n",
        "transcribed_srt_name = 'transcribed.srt' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "u9iNqUnPVkj1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2 Transcribe! Speed: ~10x\n",
        "\n",
        "segments, info = model.transcribe(filename,\n",
        "                                  beam_size=beam_size,\n",
        "                                  word_timestamps=True,\n",
        "                                  vad_filter=vad_filter,\n",
        "                                  vad_parameters={'threshold': threshold,\n",
        "                                                  'min_speech_duration_ms': min_speech_duration_ms,\n",
        "                                                  'max_speech_duration_s': max_speech_duration_s,\n",
        "                                                  'min_silence_duration_ms': min_silence_duration_ms,\n",
        "                                                  'window_size_samples': window_size_samples,\n",
        "                                                  'speech_pad_ms': speech_pad_ms},\n",
        "                                  )\n",
        "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "segments = [i for i in segments]  # force run generator\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSNemu2wV2tA",
        "outputId": "7ebce2b8-fef0-4587-c282-3c76f8fc0008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:faster_whisper:Processing audio with duration 44:35.200\n",
            "INFO:faster_whisper:VAD filter removed 07:52.320 of audio\n",
            "DEBUG:faster_whisper:VAD filter kept the following audio segments: [00:02.160 -> 00:12.928], [00:12.928 -> 00:22.736], [00:23.216 -> 00:25.680], [00:26.992 -> 00:37.344], [00:37.344 -> 00:47.648], [00:47.648 -> 00:54.480], [01:20.560 -> 01:27.184], [01:29.648 -> 01:37.680], [01:38.416 -> 01:49.696], [01:49.696 -> 01:58.864], [02:00.112 -> 02:09.744], [02:10.608 -> 02:17.424], [02:18.928 -> 02:26.000], [02:26.160 -> 02:36.480], [02:36.480 -> 02:47.904], [02:47.904 -> 02:59.280], [02:59.696 -> 03:10.592], [03:10.592 -> 03:14.256], [03:17.296 -> 03:26.928], [03:29.968 -> 03:36.976], [03:38.352 -> 03:46.064], [03:47.312 -> 03:57.760], [03:57.760 -> 03:59.312], [04:00.752 -> 04:07.184], [04:08.112 -> 04:17.504], [04:17.504 -> 04:24.912], [04:27.248 -> 04:37.584], [04:39.152 -> 04:50.592], [04:50.592 -> 05:01.776], [05:02.128 -> 05:03.440], [05:05.840 -> 05:15.984], [05:17.360 -> 05:18.736], [05:20.304 -> 05:27.360], [05:27.360 -> 05:35.888], [05:37.200 -> 05:48.416], [05:48.416 -> 05:59.264], [05:59.264 -> 06:07.824], [06:09.904 -> 06:20.928], [06:20.928 -> 06:25.424], [06:26.992 -> 06:34.176], [06:34.176 -> 06:44.304], [06:48.240 -> 06:51.664], [06:57.072 -> 06:59.408], [07:02.640 -> 07:12.592], [07:13.520 -> 07:19.952], [07:26.960 -> 07:37.104], [07:38.096 -> 07:46.064], [07:46.928 -> 07:58.464], [07:58.464 -> 08:00.272], [08:03.184 -> 08:08.848], [08:10.736 -> 08:20.896], [08:20.896 -> 08:31.952], [08:33.968 -> 08:44.608], [08:44.608 -> 08:51.920], [08:55.792 -> 09:06.384], [09:06.736 -> 09:15.584], [09:15.584 -> 09:26.208], [09:26.208 -> 09:32.624], [09:35.216 -> 09:43.824], [09:45.776 -> 09:47.856], [09:54.480 -> 09:58.480], [09:59.792 -> 10:06.800], [10:06.960 -> 10:15.440], [10:17.520 -> 10:27.232], [10:27.232 -> 10:36.576], [10:36.576 -> 10:42.144], [10:42.144 -> 10:51.920], [10:55.088 -> 10:59.280], [11:01.808 -> 11:07.408], [11:11.984 -> 11:22.368], [11:22.368 -> 11:28.144], [11:30.224 -> 11:33.456], [11:36.048 -> 11:46.896], [11:52.560 -> 11:58.736], [12:00.496 -> 12:06.672], [12:29.872 -> 12:35.280], [12:37.040 -> 12:44.560], [12:45.104 -> 12:52.112], [12:52.336 -> 13:00.944], [13:02.320 -> 13:05.552], [13:07.632 -> 13:19.456], [13:19.456 -> 13:27.184], [13:28.304 -> 13:37.168], [13:38.352 -> 13:48.496], [13:49.168 -> 13:58.800], [13:58.896 -> 14:01.936], [14:03.440 -> 14:15.056], [14:15.600 -> 14:26.192], [14:27.440 -> 14:32.016], [14:35.248 -> 14:40.976], [14:49.968 -> 14:57.040], [15:01.872 -> 15:05.184], [15:05.184 -> 15:16.640], [15:16.640 -> 15:26.032], [15:28.176 -> 15:36.016], [15:36.560 -> 15:46.272], [15:46.272 -> 15:55.920], [15:58.000 -> 16:04.768], [16:04.768 -> 16:15.520], [16:15.520 -> 16:19.216], [16:21.360 -> 16:32.000], [16:32.000 -> 16:39.120], [16:41.392 -> 16:45.456], [16:45.808 -> 16:57.440], [16:57.440 -> 17:01.968], [17:07.952 -> 17:10.608], [17:11.984 -> 17:19.248], [17:21.584 -> 17:33.216], [17:33.216 -> 17:42.736], [17:44.304 -> 17:52.656], [17:53.456 -> 18:02.336], [18:02.336 -> 18:09.488], [18:10.992 -> 18:20.560], [18:25.008 -> 18:33.088], [18:33.088 -> 18:41.936], [18:42.800 -> 18:50.048], [18:50.048 -> 19:01.456], [19:01.936 -> 19:11.632], [19:12.688 -> 19:17.520], [19:19.984 -> 19:23.856], [19:25.168 -> 19:37.168], [19:38.160 -> 19:43.440], [19:45.200 -> 19:55.152], [19:56.080 -> 20:00.016], [20:03.824 -> 20:14.304], [20:14.304 -> 20:25.184], [20:25.184 -> 20:31.568], [20:33.840 -> 20:42.512], [20:42.928 -> 20:54.432], [20:54.432 -> 20:59.856], [21:02.064 -> 21:12.672], [21:12.672 -> 21:18.224], [21:18.512 -> 21:24.560], [21:26.064 -> 21:37.104], [21:38.800 -> 21:45.824], [21:45.824 -> 21:55.152], [21:56.080 -> 21:58.672], [22:00.240 -> 22:06.416], [22:09.328 -> 22:12.048], [22:15.728 -> 22:22.080], [22:22.080 -> 22:30.032], [22:39.792 -> 22:48.208], [22:49.968 -> 22:58.528], [22:58.528 -> 23:09.520], [23:13.264 -> 23:15.280], [23:16.528 -> 23:25.392], [23:27.152 -> 23:36.784], [23:37.648 -> 23:40.624], [23:40.976 -> 23:50.672], [23:51.216 -> 23:58.800], [24:01.200 -> 24:12.752], [24:14.704 -> 24:24.992], [24:24.992 -> 24:31.824], [24:36.528 -> 24:42.832], [24:44.656 -> 24:47.056], [24:48.368 -> 24:54.032], [24:56.048 -> 25:07.680], [25:07.680 -> 25:09.840], [25:14.864 -> 25:16.432], [25:16.976 -> 25:28.000], [25:28.000 -> 25:38.640], [25:39.376 -> 25:47.280], [25:51.408 -> 26:01.792], [26:01.792 -> 26:04.368], [26:06.832 -> 26:14.672], [26:16.240 -> 26:17.872], [26:21.168 -> 26:32.288], [26:32.288 -> 26:35.728], [26:37.808 -> 26:45.456], [26:53.168 -> 27:00.624], [27:03.216 -> 27:08.624], [27:11.152 -> 27:22.784], [27:22.784 -> 27:31.008], [27:31.008 -> 27:39.040], [27:39.040 -> 27:50.496], [27:50.496 -> 27:53.744], [28:04.272 -> 28:15.456], [28:15.456 -> 28:18.256], [28:21.232 -> 28:32.256], [28:32.256 -> 28:41.248], [28:41.248 -> 28:44.048], [28:46.384 -> 28:58.064], [28:58.160 -> 29:02.032], [29:02.192 -> 29:14.016], [29:14.016 -> 29:22.576], [29:24.272 -> 29:36.272], [29:36.496 -> 29:38.128], [29:41.872 -> 29:45.808], [29:49.232 -> 30:00.720], [30:01.072 -> 30:12.432], [30:14.640 -> 30:25.360], [30:27.440 -> 30:32.080], [30:33.776 -> 30:38.672], [30:39.472 -> 30:46.400], [30:46.400 -> 30:58.016], [30:58.016 -> 31:05.744], [31:07.888 -> 31:10.160], [31:11.984 -> 31:22.720], [31:22.720 -> 31:32.768], [31:32.768 -> 31:40.640], [31:40.640 -> 31:46.000], [31:48.080 -> 31:57.696], [31:57.696 -> 32:04.704], [32:04.704 -> 32:15.888], [32:20.528 -> 32:32.160], [32:32.160 -> 32:39.504], [32:40.560 -> 32:47.936], [32:47.936 -> 32:56.528], [32:59.568 -> 33:04.720], [33:09.360 -> 33:20.592], [33:22.288 -> 33:23.920], [33:28.496 -> 33:29.552], [33:31.312 -> 33:42.080], [33:42.080 -> 33:53.616], [33:58.960 -> 34:09.040], [34:09.392 -> 34:17.552], [34:21.680 -> 34:30.672], [34:31.984 -> 34:38.928], [34:39.088 -> 34:46.880], [34:46.880 -> 34:57.360], [34:58.352 -> 35:04.400], [35:06.672 -> 35:09.968], [35:13.584 -> 35:18.160], [35:19.600 -> 35:30.560], [35:30.560 -> 35:37.376], [35:37.376 -> 35:44.912], [35:47.696 -> 35:57.184], [35:57.184 -> 36:01.744], [36:03.440 -> 36:13.056], [36:13.056 -> 36:22.560], [36:22.560 -> 36:28.768], [36:28.768 -> 36:39.376], [36:39.600 -> 36:49.360], [36:50.544 -> 36:59.792], [37:00.080 -> 37:11.120], [37:11.344 -> 37:18.864], [37:20.368 -> 37:31.600], [37:32.144 -> 37:41.024], [37:41.024 -> 37:51.248], [37:51.344 -> 38:01.984], [38:01.984 -> 38:13.600], [38:13.600 -> 38:22.624], [38:22.624 -> 38:30.224], [38:31.088 -> 38:38.928], [38:41.520 -> 38:44.624], [38:45.936 -> 38:54.432], [38:54.432 -> 38:58.448], [38:59.952 -> 39:01.840], [39:04.368 -> 39:13.376], [39:13.376 -> 39:16.368], [39:17.744 -> 39:25.392], [39:26.640 -> 39:35.952], [39:36.688 -> 39:47.856], [39:48.848 -> 39:57.392], [39:58.768 -> 40:10.128], [40:16.752 -> 40:27.984], [40:29.168 -> 40:40.800], [40:40.800 -> 40:52.064], [40:52.064 -> 40:57.680], [40:58.224 -> 41:09.856], [41:09.856 -> 41:20.832], [41:20.832 -> 41:31.792], [41:32.208 -> 41:42.032], [41:42.320 -> 41:45.536], [41:45.536 -> 41:56.576], [41:56.576 -> 42:02.704], [42:05.360 -> 42:14.096], [42:19.888 -> 42:26.384], [42:27.504 -> 42:37.456], [42:38.768 -> 42:46.864], [42:48.560 -> 43:00.192], [43:00.192 -> 43:10.784], [43:10.784 -> 43:14.128], [43:14.736 -> 43:23.040], [43:23.040 -> 43:30.848], [43:30.848 -> 43:41.248], [43:41.248 -> 43:48.432], [43:48.464 -> 43:59.376]\n",
            "INFO:faster_whisper:Detected language 'en' with probability 1.00\n",
            "DEBUG:faster_whisper:Processing segment at 00:00.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language 'en' with probability 0.998535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:faster_whisper:Processing segment at 00:26.640\n",
            "DEBUG:faster_whisper:Processing segment at 00:56.640\n",
            "DEBUG:faster_whisper:Processing segment at 01:26.620\n",
            "DEBUG:faster_whisper:Processing segment at 01:56.620\n",
            "DEBUG:faster_whisper:Processing segment at 02:26.620\n",
            "DEBUG:faster_whisper:Processing segment at 02:56.620\n",
            "DEBUG:faster_whisper:Processing segment at 03:26.620\n",
            "DEBUG:faster_whisper:Processing segment at 03:56.620\n",
            "DEBUG:faster_whisper:Processing segment at 04:26.620\n",
            "DEBUG:faster_whisper:Processing segment at 04:56.600\n",
            "DEBUG:faster_whisper:Processing segment at 05:25.560\n",
            "DEBUG:faster_whisper:Processing segment at 05:55.380\n",
            "DEBUG:faster_whisper:Processing segment at 06:25.380\n",
            "DEBUG:faster_whisper:Processing segment at 06:51.540\n",
            "DEBUG:faster_whisper:Processing segment at 07:18.800\n",
            "DEBUG:faster_whisper:Processing segment at 07:48.780\n",
            "DEBUG:faster_whisper:Processing segment at 08:16.780\n",
            "DEBUG:faster_whisper:Processing segment at 08:45.940\n",
            "DEBUG:faster_whisper:Processing segment at 09:14.300\n",
            "DEBUG:faster_whisper:Processing segment at 09:43.860\n",
            "DEBUG:faster_whisper:Processing segment at 10:12.200\n",
            "DEBUG:faster_whisper:Processing segment at 10:42.180\n",
            "DEBUG:faster_whisper:Processing segment at 11:10.400\n",
            "DEBUG:faster_whisper:Processing segment at 11:40.300\n",
            "DEBUG:faster_whisper:Processing segment at 12:10.300\n",
            "DEBUG:faster_whisper:Processing segment at 12:39.480\n",
            "DEBUG:faster_whisper:Processing segment at 13:07.760\n",
            "DEBUG:faster_whisper:Processing segment at 13:35.660\n",
            "DEBUG:faster_whisper:Processing segment at 14:03.900\n",
            "DEBUG:faster_whisper:Processing segment at 14:33.360\n",
            "DEBUG:faster_whisper:Processing segment at 15:03.320\n",
            "DEBUG:faster_whisper:Processing segment at 15:33.320\n",
            "DEBUG:faster_whisper:Processing segment at 16:03.320\n",
            "DEBUG:faster_whisper:Processing segment at 16:31.380\n",
            "DEBUG:faster_whisper:Processing segment at 17:01.120\n",
            "DEBUG:faster_whisper:Processing segment at 17:30.960\n",
            "DEBUG:faster_whisper:Processing segment at 18:00.960\n",
            "DEBUG:faster_whisper:Processing segment at 18:28.980\n",
            "DEBUG:faster_whisper:Processing segment at 18:57.540\n",
            "DEBUG:faster_whisper:Processing segment at 19:27.540\n",
            "DEBUG:faster_whisper:Processing segment at 19:57.000\n",
            "DEBUG:faster_whisper:Processing segment at 20:26.580\n",
            "DEBUG:faster_whisper:Processing segment at 20:56.580\n",
            "DEBUG:faster_whisper:Processing segment at 21:25.860\n",
            "DEBUG:faster_whisper:Processing segment at 21:55.860\n",
            "DEBUG:faster_whisper:Processing segment at 22:25.200\n",
            "DEBUG:faster_whisper:Processing segment at 22:55.200\n",
            "DEBUG:faster_whisper:Processing segment at 23:23.520\n",
            "DEBUG:faster_whisper:Processing segment at 23:52.580\n",
            "DEBUG:faster_whisper:Processing segment at 24:20.680\n",
            "DEBUG:faster_whisper:Processing segment at 24:50.680\n",
            "DEBUG:faster_whisper:Processing segment at 25:20.680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.3 Generate SRT\n",
        "\n",
        "\n",
        "import copy\n",
        "import srt\n",
        "from datetime import timedelta\n",
        "\n",
        "def sentence_segments_merger(segments, max_text_len=80, max_segment_interval=2.0):\n",
        "    \"\"\"\n",
        "    Merge sentence segments to one segment, if the length of the text is less than max_text_len.\n",
        "    :param segments: [{\"text\": \"Hello, World!\", \"start\": 1.1, \"end\": 4.4}, {\"text\": \"Hello, World!\", \"start\": 1.1, \"end\": 4.4}]\n",
        "    :type segments: list of dicts\n",
        "    :param max_text_len: Max length of the text\n",
        "    :type max_text_len: int\n",
        "    :return: Segments, but with merged sentences.\n",
        "    :rtype: list of dicts  [{\"text\": \"Hello, World! Hello, World!\", \"start\": 1.1, \"end\": 4.4}]\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return []\n",
        "\n",
        "    merged_segments = []\n",
        "    current_segment = {\"text\": \"\", \"start\": 0, \"end\": 0}\n",
        "    current_segment_template = {\"text\": \"\", \"start\": 0, \"end\": 0}\n",
        "    is_current_segment_empty = True\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        # remove empty lines\n",
        "        segment_text = segment[\"text\"].strip()\n",
        "        if not segment_text:\n",
        "            continue\n",
        "\n",
        "        if is_current_segment_empty:\n",
        "            current_segment[\"start\"] = segment[\"start\"]\n",
        "            current_segment[\"end\"] = segment[\"end\"]\n",
        "            current_segment[\"text\"] = segment[\"text\"].strip()\n",
        "            is_current_segment_empty = False\n",
        "            continue\n",
        "\n",
        "        if segment[\"start\"] - current_segment[\"end\"] < max_segment_interval and \\\n",
        "                len(current_segment[\"text\"] + \" \" + segment_text) < max_text_len:\n",
        "            current_segment[\"text\"] += \" \" + segment_text\n",
        "            current_segment[\"text\"] = current_segment[\"text\"].strip()\n",
        "            current_segment[\"end\"] = segment[\"end\"]\n",
        "        else:\n",
        "            current_segment[\"text\"] = current_segment[\"text\"].strip()\n",
        "            merged_segments.append(copy.deepcopy(current_segment))\n",
        "            current_segment = copy.deepcopy(current_segment_template)\n",
        "            is_current_segment_empty = True\n",
        "\n",
        "    return merged_segments\n",
        "\n",
        "\n",
        "segments_lst = []\n",
        "for i in segments:\n",
        "    for j in i.words:\n",
        "        if j.word.strip():  # not empty string\n",
        "            segments_lst.append({\"text\": j.word.strip(), \"start\": j.start, \"end\": j.end})\n",
        "\n",
        "result_merged = sentence_segments_merger(segments_lst,\n",
        "                                         max_text_len=max_text_len,\n",
        "                                         max_segment_interval=max_segment_interval)\n",
        "\n",
        "result_srt_list = []\n",
        "\n",
        "# if use_whisper_sentence_segment:\n",
        "#     for i, v in enumerate(segments):\n",
        "#         result_srt_list.append(srt.Subtitle(index=i,\n",
        "#                                         start=timedelta(seconds=v.start),\n",
        "#                                         end=timedelta(seconds=v.end),\n",
        "#                                         content=v.text.strip()))\n",
        "# else:\n",
        "for i, v in enumerate(result_merged):\n",
        "    result_srt_list.append(srt.Subtitle(index=i,\n",
        "                                        start=timedelta(seconds=v['start']),\n",
        "                                        end=timedelta(seconds=v['end']),\n",
        "                                        content=v['text'].strip()))\n",
        "\n",
        "composed_transcription = srt.compose(result_srt_list)\n",
        "\n",
        "with open(transcribed_srt_name, 'w') as f:\n",
        "    f.write(composed_transcription)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Whn0t6giYjg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see a srt file generated with desired name: right click and download the file."
      ],
      "metadata": {
        "id": "JJz880Ukmp3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4 Optional: Peek the SRT file\n",
        "print(composed_transcription)"
      ],
      "metadata": {
        "id": "JYDrG20-hFEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Translate"
      ],
      "metadata": {
        "id": "RPczRP3dmt4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6.1 Import packages\n",
        "import requests\n",
        "import random\n",
        "from hashlib import md5\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
        "from googletrans import Translator\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "\n",
        "def translate_via_googletrans(content):\n",
        "    try:\n",
        "        resp = google_translator(content, src=source_lang.lower(), dest=target_lang.lower()).text\n",
        "    except Exception as e:\n",
        "        print(content)\n",
        "        print(e)\n",
        "        return ''\n",
        "\n",
        "    return resp\n",
        "\n",
        "\n",
        "# def translate_via_gmx(content):\n",
        "#     try:\n",
        "#         resp = s.get('https://search.gmx.com/translate', params={\"q\": content, \"source\": source_lang.lower(), \"target\": target_lang.lower(), \"lang\": 'en', \"reload\": \"true\"}).json()\n",
        "#     except Exception as e:\n",
        "#         print(content)\n",
        "#         print(e)\n",
        "#         return ''\n",
        "\n",
        "#     return resp['Translation']\n",
        "\n",
        "\n",
        "def translate_via_deepl_backup(content):\n",
        "    try:\n",
        "        resp = s.post('https://deepl.cnbeining.com/translate', json={\"text\": content, \"source_lang\": source_lang, \"target_lang\": target_lang}).json()\n",
        "    except Exception as e:\n",
        "        print(content)\n",
        "        print(e)\n",
        "        if resp['code'] != 200:\n",
        "            print('Error calling API: ')\n",
        "            print(resp)\n",
        "        return ''\n",
        "\n",
        "    return resp['result']['texts'][0]['text']\n",
        "\n",
        "\n",
        "def translate_via_baidu(content):\n",
        "    app_id = '20221011001385250'\n",
        "    secret_key = 'J1qY4VXuCF9QOeumC_R4'\n",
        "    salt = random.randint(32768, 65536)\n",
        "    temp_str = app_id + content + str(salt) + secret_key\n",
        "    sign = md5(temp_str.encode('utf-8')).hexdigest()\n",
        "    payload = {'appid': app_id, 'q': content, 'from': source_lang.lower(), 'to': target_lang.lower(), 'salt': salt, 'sign': sign}\n",
        "    try:\n",
        "        resp = s.post('http://api.fanyi.baidu.com/api/trans/vip/translate', params=payload).json()\n",
        "    except Exception as e:\n",
        "        print(content)\n",
        "        print(e)\n",
        "        return ''\n",
        "\n",
        "    return resp['trans_result'][0]['dst']\n",
        "\n",
        "translation_function = translate_via_deepl_backup\n",
        "\n"
      ],
      "metadata": {
        "id": "_2ND-Ay_mvMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6.2 Setup Variables: Thread Number, Source Language, Target Language\n",
        "\n",
        "result_list_translated = []\n",
        "result_list_assembled = []\n",
        "s = requests.Session()\n",
        "google_translator = Translator()\n",
        "\n",
        "\n",
        "chunk_size = 8 #@param {type:\"integer\"}\n",
        "thread_num = 12 #@param {type:\"integer\"}\n",
        "source_lang = \"RU\" #@param [\"auto\", \"BG\", \"CS\", \"DA\", \"DE\", \"EL\", \"EN\", \"EN-GB\", \"EN-US\", \"ES\", \"ET\", \"FI\", \"FR\", \"HU\", \"ID\", \"IT\", \"JA\", \"LT\", \"LV\", \"NL\", \"PL\", \"PT\", \"PT-BR\", \"PT-PT\", \"RO\", \"RU\", \"SK\", \"SL\", \"SV\", \"TR\", \"UK\", \"ZH\"]\n",
        "target_lang = \"RU\" #@param [\"BG\", \"CS\", \"DA\", \"DE\", \"EL\", \"EN\", \"EN-GB\", \"EN-US\", \"ES\", \"ET\", \"FI\", \"FR\", \"HU\", \"ID\", \"IT\", \"JA\", \"LT\", \"LV\", \"NL\", \"PL\", \"PT\", \"PT-BR\", \"PT-PT\", \"RO\", \"RU\", \"SK\", \"SL\", \"SV\", \"TR\", \"UK\", \"ZH\"]\n",
        "translation_engine = \"deepl_backup\" #@param [\"py-googletrans\", \"deepl_backup\", \"baidu-api\"]\n",
        "\n",
        "baidu_app_id = '20221011001385250' #@param {type:\"string\"}\n",
        "baidu_secret_key = 'J1qY4VXuCF9QOeumC_R4' #@param {type:\"string\"}\n",
        "\n",
        "remove_special_chars_acicfg = True #@param {type:\"boolean\"}\n",
        "\n",
        "translated_result_filename = 'translated.srt' #@param {type:\"string\"}\n",
        "is_generate_assembled_srt = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Hacking Google results\n",
        "if target_lang == \"ZH\" and translation_engine == \"py-googletrans\":\n",
        "    target_lang = \"zh-cn\"\n"
      ],
      "metadata": {
        "id": "qAT2t68fmzz8",
        "cellView": "form"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `thread_num`: Number of threads. Too high may cause throtting.\n",
        "- `source_lang`, `target_lang`: Language code, See [ISO_639-1 codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)\n",
        "- `translation_engine`:\n",
        "  - `deepl_gmx`: Powered by GMX and DeepL. Data governance: Germany\n",
        "  - `py-googletrans`: Powered by unofficial Google Translate AJAX API. Data governance: US\n",
        "  - `deepl_backup`: Powered by ACICFG with DeepL. Data governance: Canada and Germany although no log is kept on ACICFG's server.\n",
        "  - `baidu-api`: Powered by [Baidu Fanyi](http://api.fanyi.baidu.com/). Data governance: Mainland China\n",
        "- `baidu_app_id` and `baidu_secret_key` are optional - only required when you use `baidu-api`.\n",
        "- `remove_special_chars_acicfg`: Remove special chars per ACICFG's standard.\n",
        "- `translated_result_filename`: Filename of SRT to generate.\n",
        "- `is_generate_assembled_srt`: Generated SRT that has 2 lines - translation then original."
      ],
      "metadata": {
        "id": "JCaY00uMm9A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6.3 Translation: ~1.2 x thread number lines/sec when single threaded\n",
        "\n",
        "# if translation_engine == \"deepl_gmx\":\n",
        "#     translation_function = translate_via_gmx\n",
        "if translation_engine == \"deepl_backup\":\n",
        "    translation_function = translate_via_deepl_backup\n",
        "elif translation_engine == \"py-googletrans\":\n",
        "    translation_function = translate_via_googletrans\n",
        "elif translation_engine == \"baidu-api\":\n",
        "    translation_function = translate_via_baidu\n",
        "\n",
        "\n",
        "source_texts = [line['text'].strip() for line in result_merged]\n",
        "# preprocess source texts\n",
        "source_text_chunks = list(chunks(source_texts, int(chunk_size)))\n",
        "source_text_chunks_merged = ['\\n------\\n'.join(chunk) for chunk in source_text_chunks]\n",
        "\n",
        "result_list_translated = []\n",
        "result_api_call = Parallel(n_jobs=thread_num, verbose=10)(delayed(translation_function)(chunk) for chunk in source_text_chunks_merged)\n",
        "\n",
        "for chunk, original_text in zip(result_api_call, source_text_chunks_merged):\n",
        "    chunk = [i.strip() for i in chunk.split('------')] # in case the translator messes up the line breaks\n",
        "    if len(chunk) != chunk_size:\n",
        "        print(chunk)\n",
        "        print(original_text)\n",
        "    result_list_translated.extend(chunk)\n",
        "\n",
        "print(f\"Translated {len(result_list_translated)} lines.\")\n",
        "\n",
        "# Assemble SRT\n",
        "for i, j in zip(source_texts, result_list_translated):\n",
        "    result_list_assembled.append(f\"{j}\\n{i}\")\n",
        "\n",
        "result_srt_list_translated = []\n",
        "\n",
        "for i, v in enumerate(result_merged):\n",
        "    result_srt_list_translated.append(srt.Subtitle(index=i, start=timedelta(seconds=v['start']), end=timedelta(seconds=v['end']), content=result_list_translated[i]))\n",
        "\n",
        "result_srt_list_assembled = []\n",
        "\n",
        "for i, v in enumerate(result_merged):\n",
        "    result_srt_list_assembled.append(srt.Subtitle(index=i, start=timedelta(seconds=v['start']), end=timedelta(seconds=v['end']), content=result_list_assembled[i]))\n",
        "\n",
        "composed_transcription_translated = srt.compose(result_srt_list_translated)\n",
        "composed_transcription_assembled = srt.compose(result_srt_list_assembled)\n",
        "\n",
        "\n",
        "# remove special chars\n",
        "if remove_special_chars_acicfg:\n",
        "    composed_transcription_translated = composed_transcription_translated.replace(\"。\", \"\").replace(\"，\", \" \").replace(\"、\", \" \")\n",
        "    composed_transcription_assembled = composed_transcription_assembled.replace(\"。\", \"\").replace(\"，\", \" \").replace(\"、\", \" \")\n",
        "\n",
        "\n",
        "# Write SRT\n",
        "with open(translated_result_filename, 'w') as f:\n",
        "    if is_generate_assembled_srt:\n",
        "        f.write(composed_transcription_assembled)\n",
        "    else:\n",
        "        f.write(composed_transcription_translated)"
      ],
      "metadata": {
        "id": "3nx3WlHFnLmp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: Execute the cell below to peak the assembled results.\n",
        "print(composed_transcription_assembled)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yk5dME2Cne2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optional: xterm\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!pip install colab-xterm\n",
        "\n",
        "%load_ext colabxterm\n",
        "%xterm"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RUdCi2Vnqb6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recycle Bin\n",
        "\n",
        "For developer only."
      ],
      "metadata": {
        "id": "ADIruLQhovOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unused: Single Threaded version\n",
        "\n",
        "\n",
        "with tqdm(total=len(result['segments'])) as pbar:\n",
        "    for line in result['segments']:\n",
        "        content = line['text'].strip()\n",
        "        try:\n",
        "            resp = s.post('https://deepl.cnbeining.com/translate', json={\"text\": content, \"source_lang\": \"auto\", \"target_lang\": \"ZH\"}).json()\n",
        "            result_list_translated.append(resp['data'])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(line)\n",
        "            print(e)\n",
        "            if resp['code'] != 200:\n",
        "                print('Error calling API: ' + resp['msg'])\n",
        "            result_list_translated.append(content)\n",
        "            result_list_assembled.append(content)\n",
        "            continue\n",
        "\n",
        "\n",
        "        result_list_translated.append(resp['data'])\n",
        "        result_list_assembled.append(f\"{resp['data']}\\n{content}\")\n",
        "\n",
        "        pbar.update(1)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZAt2GqR5os3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.1 Import helpers\n",
        "\n",
        "\n",
        "def word_segment_to_sentence(segments):\n",
        "    \"\"\"\n",
        "    Convert word segments to sentences.\n",
        "    :param segments: [{\"text\": \"Hello,\", \"start\": 1.1, \"end\": 2.2}, {\"text\": \"World!\", \"start\": 3.3, \"end\": 4.4}]\n",
        "    :type segments: list of dicts\n",
        "    :return: Segments, but with sentences instead of words.\n",
        "    :rtype: list of dicts  [{\"text\": \"Hello, World!\", \"start\": 1.1, \"end\": 4.4}]\n",
        "    \"\"\"\n",
        "    end_of_sentence_symbols = tuple(['.', '!', '?'])\n",
        "    sentence_results = []\n",
        "\n",
        "    current_sentence = {\"text\": \"\", \"start\": 0, \"end\": 0}\n",
        "    current_sentence_template = {\"text\": \"\", \"start\": 0, \"end\": 0}\n",
        "\n",
        "    for segment in segments:\n",
        "        if current_sentence[\"text\"] == \"\":\n",
        "            current_sentence[\"start\"] = segment[\"start\"]\n",
        "        current_sentence[\"text\"] += segment[\"text\"].strip() + ' '\n",
        "        current_sentence[\"end\"] = segment[\"end\"]\n",
        "        if segment[\"text\"][-1].strip() in end_of_sentence_symbols:\n",
        "            current_sentence[\"text\"] = current_sentence[\"text\"].strip()\n",
        "            sentence_results.append(copy.deepcopy(current_sentence))\n",
        "            current_sentence = copy.deepcopy(current_sentence_template)\n",
        "    return sentence_results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LEBC-FfZhDpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}